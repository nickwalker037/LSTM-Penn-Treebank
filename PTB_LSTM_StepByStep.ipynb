{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> LSTM Model - Penn Treebank Dataset </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we break the model out into every individual step so that we can gain a better understanding of how they work -- and later combine them into one LSTM Model Class - located in other file \"WordEmbeddings_LSTM\"\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "We'll make use of word embeddings -- a way of representing sentence structures or words as n-dimensional vectors of real numbers\n",
    "- So we pretty much assign each word a randomly-initialized vector, and input those into the network to be processed\n",
    "\n",
    "And after iterating through our model, the vectors assume values that help the network correctly predict what it needs to (the probable next word in the sentence)\n",
    "- It will group words in a similar fashion to this picture below (i.e. words that are frequently used together are grouped together): <br>\n",
    "<img src=\"https://ibm.box.com/shared/static/bqhc5dg879gcoabzhxra1w8rkg3od1cu.png\" width=\"500\">\n",
    "<i>Source: IBM </i>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Get Data: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Penn Treebank dataset from IBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "Archive:  data/ptb.zip\n",
      "  inflating: data/ptb/reader.py      \n",
      "  inflating: data/__MACOSX/ptb/._reader.py  \n",
      "  inflating: data/__MACOSX/._ptb     \n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget -q -O data/ptb.zip https://ibm.box.com/shared/static/z2yvmhbskc45xd2a9a4kkn6hg4g4kj5r.zip\n",
    "!unzip -o data/ptb.zip -d data\n",
    "!cp data/ptb/reader.py .\n",
    "\n",
    "import reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download simple examples dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-08 15:26:43--  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
      "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 2001:67c:1220:809::93e5:917\n",
      "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34869662 (33M) [application/x-gtar]\n",
      "Saving to: ‘simple-examples.tgz.4’\n",
      "\n",
      "simple-examples.tgz 100%[=====================>]  33.25M  3.69MB/s   in 10s    \n",
      "\n",
      "2019-03-08 15:26:54 (3.28 MB/s) - ‘simple-examples.tgz.4’ saved [34869662/34869662]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz \n",
    "!tar xzf simple-examples.tgz -C data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Building the LSTM Model: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define the model's hypterparameters so that we can practice playing around with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_scale = 0.1                  # initial weight scale\n",
    "learning_rate = 1.0               # initial learning weight\n",
    "max_grad_norm = 5                 # max permissible norm for the gradient -- for Gradient Clipping\n",
    "num_layers = 2                    # number of layers in our model\n",
    "num_steps = 20                    # total number of recurrence steps \n",
    "\n",
    "hidden_size_l1 = 256              # number of neurons (processing units) in the hidden layers\n",
    "hidden_size_l2 = 128\n",
    "\n",
    "max_epoch_decay_lr = 4            # max number of epochs trained with the initial learning weight\n",
    "max_epoch = 15                    # total epochs in training\n",
    "\n",
    "keep_prob = 1                     # probability of keeping data in the Dropout layer\n",
    "decay = 0.5                       # the decay for the learning rate\n",
    "batch_size = 60                   # size for each batch of data\n",
    "vocab_size = 10000                # vocab size\n",
    "embedding_vector_size = 200       \n",
    "\n",
    "is_training = 1                   # training flag to separate training from testing\n",
    "data_dir = \"data/simple-examples/data/\" # data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the structure is like:\n",
    "    - 200 input units -> [200x256] Weight -> 256 Hidden units (first layer) -> [256x128] Weight matrix  -> 128 Hidden units (second layer) ->  [128x200] weight Matrix -> 200 unit output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Train Data: </h4>\n",
    "Train data is a list of words, of size 929589, represented by numbers, e.g. [9971, 9972, 9974, 9975,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start an interactive session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads the data and separates it into train, validation, and test datasets\n",
    "raw_data = reader.ptb_raw_data(data_dir)\n",
    "train_data, valid_data, test_data, vocab, word_to_id = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data:  929589\n",
      "Length of validation data:  73760\n",
      "Length of test data:  82430\n",
      "Length of vocab:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of training data: \", len(train_data))\n",
    "print(\"Length of validation data: \", len(valid_data))\n",
    "print(\"Length of test data: \", len(test_data))\n",
    "print(\"Length of vocab: \", vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Define a function to translate id's back to their respective words:</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_word(id_list):\n",
    "    line = []\n",
    "    for w in id_list:\n",
    "        for word, wid in word_to_id.items():\n",
    "            if wid == w:\n",
    "                line.append(word)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984, 9986, 9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 2, 9256, 1, 3, 72, 393, 33, 2133, 0, 146, 19, 6, 9207, 276, 407, 3, 2, 23, 1, 13, 141, 4, 1, 5465, 0, 3081, 1596, 96, 2, 7682, 1, 3, 72, 393, 8, 337, 141, 4, 2477, 657, 2170, 955, 24, 521, 6, 9207, 276, 4, 39, 303, 438, 3684, 2, 6, 942, 4, 3150, 496, 263, 5, 138, 6092, 4241, 6036, 30, 988, 6, 241, 760, 4, 1015, 2786, 211, 6, 96, 4]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', 'N', '<eos>', 'mr.', '<unk>', 'is', 'chairman', 'of', '<unk>', 'n.v.', 'the', 'dutch', 'publishing', 'group', '<eos>', 'rudolph', '<unk>', 'N', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '<eos>', 'a', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of']\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word(train_data[0:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Reading one mini-batch and feeding our network: </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "itera = reader.ptb_iterator(train_data, batch_size, num_steps)\n",
    "first_tuple = itera.__next__()\n",
    "x = first_tuple[0]\n",
    "y = first_tuple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at 3 sentences of our input x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984,\n",
       "        9986, 9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995],\n",
       "       [ 901,   33, 3361,    8, 1279,  437,  597,    6,  261, 4276, 1089,\n",
       "           8, 2836,    2,  269,    4, 5526,  241,   13, 2420],\n",
       "       [2654,    6,  334, 2886,    4,    1,  233,  711,  834,   11,  130,\n",
       "         123,    7,  514,    2,   63,   10,  514,    8,  605]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the same 3 sentences in words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim']\n",
      "['test', 'will', 'concentrate', 'and', 'sometimes', 'give', 'away', 'a', 'few', 'exact', 'questions', 'and', 'answers', '<eos>', 'use', 'of', 'scoring', 'high', 'is', 'widespread']\n",
      "['color', 'a', 'second', 'round', 'of', '<unk>', 'economic', 'talks', 'scheduled', 'for', 'next', 'week', 'in', 'washington', '<eos>', 'not', 'that', 'washington', 'and', 'tokyo']\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word(x[0]))\n",
    "print(id_to_word(x[1]))\n",
    "print(id_to_word(x[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Define 2 placeholders to feed them with mini-batches (x and y): </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input_data = tf.placeholder(tf.int32, [batch_size, num_steps]) # [30, 20]\n",
    "_targets = tf.placeholder(tf.int32, [batch_size, num_steps]) # [30, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a dictionary to feed the placeholders with our first mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {_input_data:x, _targets:y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For example, we can use it to feed <code>\\_input\\_data</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9970, 9971, 9972, ..., 9993, 9994, 9995],\n",
       "       [ 901,   33, 3361, ...,  241,   13, 2420],\n",
       "       [2654,    6,  334, ...,  514,    8,  605],\n",
       "       ...,\n",
       "       [7831,   36, 1678, ...,    4, 4558,  157],\n",
       "       [  59, 2070, 2433, ...,  400,    1, 1173],\n",
       "       [2097,    3,    2, ..., 2043,   23,    1]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(_input_data, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create the Stacked LSTM: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell_l1 = tf.contrib.rnn.BasicLSTMCell(hidden_size_l1, forget_bias=0.0)\n",
    "lstm_cell_l2 = tf.contrib.rnn.BasicLSTMCell(hidden_size_l2, forget_bias=0.0)\n",
    "stacked_lstm = tf.contrib.rnn.MultiRNNCell([lstm_cell_l1, lstm_cell_l2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Initialize the states of the network: </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 state matrices:\n",
    "<ul>\n",
    "    <li> Memory State: m_state </li>\n",
    "    <li> Cell State: c_state </li>\n",
    "</ul>\n",
    "Each hidden layer has a vector of size 30 which keeps the states. So for 256 hidden units we have a matrix of size [30x256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(60, 256) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(60, 256) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(60, 128) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(60, 128) dtype=float32>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_initial_state = stacked_lstm.zero_state(batch_size, tf.float32)\n",
    "_initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the states, even though they're all 0 for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), h=array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)),\n",
       " LSTMStateTuple(c=array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), h=array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(_initial_state, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating Word Embeddings </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical approach is to use the one-hot encoding method to convert the words in our dataset to vectors of numbers. This creates a high-dimensional sparse dataset, but is also inefficient when working with such large datasets. \n",
    "<br>\n",
    "<br>\n",
    "Thus, we'll use the word2vec approach. And we'll represent this as a layer in our LSTM where the word IDs will be represented as a dense representation before feeding into the LSTM \n",
    "<br> \n",
    "<br>\n",
    "<b>Note:</b> The embedding vectors will also get updated during the training process of the deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vocab = tf.get_variable(\"embedding_vocab\", [vocab_size, embedding_vector_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the <code>embedding_words</code> with random values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0213737 , -0.00334409, -0.01018565, ..., -0.01020918,\n",
       "         0.02334081,  0.00289541],\n",
       "       [-0.00548434, -0.02135967,  0.01319274, ..., -0.00279438,\n",
       "         0.01150737, -0.00271155],\n",
       "       [-0.00017232, -0.01461577, -0.00689847, ...,  0.00439154,\n",
       "         0.00612313, -0.0164778 ],\n",
       "       ...,\n",
       "       [-0.0209833 ,  0.00340537,  0.01616802, ...,  0.02202382,\n",
       "        -0.00369697, -0.02364882],\n",
       "       [-0.00075741,  0.00768025,  0.01728018, ...,  0.01072704,\n",
       "        -0.00530361, -0.01803417],\n",
       "       [-0.00375612, -0.022914  ,  0.00630276, ...,  0.01526984,\n",
       "        -0.01173498,  0.00300352]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(embedding_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below \n",
    "<code>embedding_lookup()</code> finds the embedded values for our batch of 60x20 words.\n",
    "<br>\n",
    "<br>\n",
    "it goes to each row of <code>input_data</code> and for each word in the row/sentence it finds the corresponding vector in <code>embedding_dict</code>\n",
    "<br>\n",
    "<br>\n",
    "it creates a [60,20,200] tensor. i.e. the first element of <b>inputs</b> (the first sentence), is a matrix of [20x200], where each row is a vector representing the word in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(60, 20, 200) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.nn.embedding_lookup(embedding_vocab, _input_data) #shape = (60, 20, 200)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01636498,  0.01951164, -0.01602272, ..., -0.02367425,\n",
       "         0.01455395, -0.01347792],\n",
       "       [ 0.00582112, -0.01481521, -0.00915285, ..., -0.00859324,\n",
       "        -0.0011811 ,  0.01254718],\n",
       "       [-0.01520363, -0.01240561, -0.00730615, ...,  0.0145461 ,\n",
       "        -0.0126853 ,  0.02235372],\n",
       "       ...,\n",
       "       [ 0.00772456, -0.023672  , -0.01346414, ..., -0.01951801,\n",
       "         0.01067849, -0.00712226],\n",
       "       [-0.00237579,  0.00305569,  0.01819591, ...,  0.00439961,\n",
       "        -0.0165371 ,  0.01986329],\n",
       "       [-0.02240466, -0.01714158,  0.02011445, ..., -0.01531839,\n",
       "         0.0086587 ,  0.00743859]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(inputs[0], feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Contructing the Recurrent Neural Network: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>tf.nn.dynamic_rnn()</code> creates a RNN using <code>stacked_lstm</code>\n",
    "<br>\n",
    "the input should be a tensor of shape: [batch_size, max_time, embedding_vector_size] -- here it's (60, 20, 200)\n",
    "<br>\n",
    "<br>\n",
    "This method returns a pair (outputs, new_state) where:\n",
    "- <b>outputs:</b> is a length T list of outputs (one for each input), or a nested tuple of such elements\n",
    "- <b>new_state:</b> is the final state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, new_state = tf.nn.dynamic_rnn(stacked_lstm, inputs, initial_state=_initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/transpose_1:0' shape=(60, 20, 128) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.9406323e-05,  3.9944524e-04,  6.3427855e-05, ...,\n",
       "        -7.7575125e-04, -3.1275125e-04,  6.1279177e-05],\n",
       "       [ 5.5325805e-04,  4.5826728e-04,  2.3342554e-04, ...,\n",
       "        -4.8883003e-04, -7.5739459e-04,  2.6636335e-04],\n",
       "       [ 4.2421496e-04,  8.5593783e-04,  4.4784762e-04, ...,\n",
       "        -5.8149017e-04, -4.1002306e-04,  2.9800067e-04],\n",
       "       ...,\n",
       "       [-3.0399158e-04,  9.3412941e-04,  9.2715595e-04, ...,\n",
       "        -1.3110086e-03,  7.7368328e-05,  9.3800321e-05],\n",
       "       [ 3.0067988e-04,  2.1566251e-04,  7.6333305e-04, ...,\n",
       "        -6.6103722e-04,  3.9553220e-04,  1.4844591e-04],\n",
       "       [ 8.5739687e-04, -4.5345520e-04,  7.0111483e-04, ...,\n",
       "        -8.6387061e-04,  1.3594154e-03, -1.5523579e-04]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(outputs[0], feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need to flatten the outputs so we can connect it to our softmax layer. Let's reshape it from [60 x 20 x 200] to [1200 x 200]\n",
    "<br>\n",
    "<br>\n",
    "<b>To do this:</b> Imagine our output is 3-d tensor as following (of course each <code>sen_x_word_y</code> is an embedded vector by itself): \n",
    "<ul>\n",
    "    <li>sentence 1: [[sen1word1], [sen1word2], [sen1word3], ..., [sen1word20]]</li> \n",
    "    <li>sentence 2: [[sen2word1], [sen2word2], [sen2word3], ..., [sen2word20]]</li>   \n",
    "    <li>sentence 3: [[sen3word1], [sen3word2], [sen3word3], ..., [sen3word20]]</li>  \n",
    "    <li>...  </li>\n",
    "    <li>sentence 30: [[sen30word1], [sen30word2], [sen30word3], ..., [sen30word20]]</li>   \n",
    "</ul>\n",
    "Now, the flatten would convert this 3-dim tensor to:\n",
    "\n",
    "[ [sen1word1], [sen1word2], [sen1word3], ..., [sen1word20],[sen2word1], [sen2word2], [sen2word3], ..., [sen2word20], ..., [sen30word20] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(1200, 128) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.reshape(outputs, [-1, hidden_size_l2])\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating Logistic Unit </h3>\n",
    "- this will return the probability of the output word in our vocabulary of 10,000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_w = tf.get_variable(\"softmax_w\", [hidden_size_l2, vocab_size]) #[256x10,000]\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [vocab_size]) #[1x10,000]\n",
    "logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "prob = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the probability of observing words for t=0 to t=20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the output:  (1200, 10000)\n",
      "probability of observing words in the range t=0 to t=20:  [[9.84885410e-05 9.83528225e-05 9.99198164e-05 ... 9.86349187e-05\n",
      "  1.01478494e-04 9.95689697e-05]\n",
      " [9.84855214e-05 9.83500722e-05 9.99271215e-05 ... 9.86392624e-05\n",
      "  1.01486527e-04 9.95785231e-05]\n",
      " [9.84893923e-05 9.83557402e-05 9.99320910e-05 ... 9.86375089e-05\n",
      "  1.01487371e-04 9.95713781e-05]\n",
      " ...\n",
      " [9.84974104e-05 9.83587524e-05 9.99250260e-05 ... 9.86395607e-05\n",
      "  1.01486046e-04 9.95751252e-05]\n",
      " [9.84975923e-05 9.83535210e-05 9.99231052e-05 ... 9.86348750e-05\n",
      "  1.01490121e-04 9.95790542e-05]\n",
      " [9.84945582e-05 9.83526697e-05 9.99238327e-05 ... 9.86357627e-05\n",
      "  1.01485304e-04 9.95770024e-05]]\n"
     ]
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "output_words_prob = session.run(prob, feed_dict)\n",
    "print(\"shape of the output: \", output_words_prob.shape)\n",
    "print(\"probability of observing words in the range t=0 to t=20: \", output_words_prob[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Prediction </h3>\n",
    "- what is the word corresponding to the maximum probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3261, 3744, 3261, 6397, 9649, 9649, 9649, 6947, 4475,  445, 6397,\n",
       "       6397,  780, 6397, 8792,  780, 2971, 8792, 8792, 8792])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output_words_prob[0:20], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is the ground truth for the first word of the first sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984, 9986,\n",
       "       9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995, 9996], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and you can get that same ground truth using the <b>target</b> tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984, 9986,\n",
       "       9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995, 9996], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ = session.run(_targets, feed_dict)\n",
    "targ[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Defining the Objective Function </h3>\n",
    "- we minimize the loss function -- the average negative log probability of the target words:\n",
    "$$\\text{loss} = -\\frac{1}{N}\\sum_{i=1}^{N} \\ln p_{\\text{target}_i}$$\n",
    "this function can be implemented in tensorflow through <code>sequence_loss_by_example</code>. it calculates the weighted cross-entropy loss for <b>logits</b> and <b>target</b> sequence\n",
    "<br>\n",
    "<br>\n",
    "The arguments of this function are:\n",
    "<ul>\n",
    "    <li>logits: List of 2D Tensors of shape [batch_size x num_decoder_symbols].</li>  \n",
    "    <li>targets: List of 1D batch-sized int32 Tensors of the same length as logits.</li>   \n",
    "    <li>weights: List of 1D batch-sized float-Tensors of the same length as logits.</li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [tf.reshape(_targets, [-1])],[tf.ones([batch_size * num_steps])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first 10 values for loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.219284, 9.21556 , 9.201283, 9.207876, 9.213242, 9.21275 ,\n",
       "       9.194984, 9.193851, 9.211199, 9.226957], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(loss, feed_dict)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss as the average of all losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184.19221"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_sum(loss) / batch_size\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(cost, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training our Model</h3>\n",
    "\n",
    "We take the following steps to train our model:\n",
    "<ol>\n",
    "    <li>Define the optimizer.</li>\n",
    "    <li>Extract variables that are trainable.</li>\n",
    "    <li>Calculate the gradients based on the loss function.</li>\n",
    "    <li>Apply the optimizer to the variables/gradients tuple.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> 1. Define the Optimizer </h5>\n",
    "- Here we'll use the gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable for the learning rate\n",
    "lr = tf.Variable(0.0, trainable=False)\n",
    "\n",
    "# Create optimizer with our learning rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> 2. Extract Trainable Variables </h5>\n",
    "- if you passed <code>trainable=True</code>, the variable constructor automatically adds the variable to the graph collection <b>GraphKeys.TRAINABLE_VARIABLES</b>. With <code>tf.trainable_variables()</code> you can get all the variables created with <code>trainable=True</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_vocab:0' shape=(10000, 200) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(456, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(384, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_w:0' shape=(128, 10000) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_b:0' shape=(10000,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "tvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding_vocab:0',\n",
       " 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0',\n",
       " 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0',\n",
       " 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0',\n",
       " 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0',\n",
       " 'softmax_w:0',\n",
       " 'softmax_b:0']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tvars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Calculate Gradients based on Loss Function </h5>\n",
    "- Gradient -- is calculated the same way as taking the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.framework.ops.IndexedSlices at 0x7f2b800b9c50>,\n",
       " <tf.Tensor 'gradients/rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/MatMul/Enter_grad/b_acc_3:0' shape=(456, 1024) dtype=float32>,\n",
       " <tf.Tensor 'gradients/rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_3:0' shape=(1024,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/MatMul/Enter_grad/b_acc_3:0' shape=(384, 512) dtype=float32>,\n",
       " <tf.Tensor 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_3:0' shape=(512,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/MatMul_grad/MatMul_1:0' shape=(128, 10000) dtype=float32>,\n",
       " <tf.Tensor 'gradients/add_grad/Reshape_1:0' shape=(10000,) dtype=float32>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gradients(cost, tvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_t_list = tf.gradients(cost, tvars)\n",
    "#session.run(grad_t_list, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have a list of tensorts - grad_t_list. We can use it to find clipped tensors. <code>clip_by_global_norm</code> clips values of multiple tensors by the ratio of the sum of their norms.\n",
    "<br>\n",
    "<br>\n",
    "<code>clip_by_global_norm</code> takes t-list as input and returns 2 things:\n",
    "- a list of clipped tensors -- called <i>list_clipped</i>\n",
    "- the global norm of all tensors in t-list -- called <i>global_norm</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.framework.ops.IndexedSlices at 0x7f2b800ad0f0>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_1:0' shape=(456, 1024) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_2:0' shape=(1024,) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_3:0' shape=(384, 512) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_4:0' shape=(512,) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_5:0' shape=(128, 10000) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_6:0' shape=(10000,) dtype=float32>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the gradiet clipping threshold:\n",
    "grads, _ = tf.clip_by_global_norm(grad_t_list, max_grad_norm)\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IndexedSlicesValue(values=array([[ 2.5460706e-06, -1.5599641e-06, -5.0178919e-06, ...,\n",
       "         -5.1370648e-06,  1.2168175e-06, -8.8229208e-06],\n",
       "        [ 3.5357975e-06, -5.6158678e-06, -1.0667203e-06, ...,\n",
       "          4.7822709e-07,  7.7584300e-06, -8.2193346e-06],\n",
       "        [ 1.1310232e-06, -4.9726486e-06,  9.2283102e-08, ...,\n",
       "         -1.9307936e-06, -9.7034885e-08, -7.8395706e-06],\n",
       "        ...,\n",
       "        [-4.5345719e-06, -1.0879848e-05, -1.1152408e-05, ...,\n",
       "         -8.4349831e-06, -6.2263553e-06,  9.7209504e-06],\n",
       "        [-2.4112430e-06, -8.7081917e-06, -9.6059503e-06, ...,\n",
       "         -5.9034192e-06, -4.0739587e-06,  1.1668343e-05],\n",
       "        [-1.5840376e-06,  1.0775825e-06, -5.2606206e-06, ...,\n",
       "         -1.6369095e-06, -8.3876294e-06,  1.0226038e-06]], dtype=float32), indices=array([9970, 9971, 9972, ..., 2043,   23,    1], dtype=int32), dense_shape=array([10000,   200], dtype=int32)),\n",
       " array([[-8.5344025e-09, -1.0975511e-08,  4.0865434e-08, ...,\n",
       "          4.1109509e-08, -3.0001356e-08,  3.0708197e-08],\n",
       "        [-2.2285123e-08,  3.3315096e-08,  5.1093405e-09, ...,\n",
       "         -4.8452060e-09,  4.5729450e-08,  2.0670976e-10],\n",
       "        [-6.0254031e-08,  1.6009022e-08, -6.6478393e-08, ...,\n",
       "          1.7094598e-08,  1.5724570e-08, -8.8944168e-09],\n",
       "        ...,\n",
       "        [-8.0390805e-10,  2.0121946e-09,  2.0083399e-09, ...,\n",
       "         -6.6885875e-09,  4.7783538e-10,  8.9503371e-10],\n",
       "        [ 2.6274880e-09, -3.9298351e-09, -4.3441681e-09, ...,\n",
       "         -1.5628823e-09,  6.3678209e-09,  1.2475817e-09],\n",
       "        [ 5.2026770e-09, -3.1917189e-09, -2.3585223e-09, ...,\n",
       "          4.6475463e-09,  5.7465743e-10, -2.9116765e-10]], dtype=float32),\n",
       " array([ 1.0799068e-06,  1.0835514e-06, -1.0497664e-06, ...,\n",
       "        -1.7689888e-06, -2.9012023e-07, -2.2741945e-06], dtype=float32),\n",
       " array([[-2.21446042e-10,  6.86833523e-09,  4.28531521e-09, ...,\n",
       "          8.57708216e-09, -4.58013583e-09,  2.30837971e-09],\n",
       "        [-6.58518173e-09,  4.85393281e-09,  3.76634723e-09, ...,\n",
       "         -9.50260493e-09,  8.19359336e-09,  3.75018416e-09],\n",
       "        [ 5.43865664e-09, -2.32197639e-09, -1.04784688e-08, ...,\n",
       "         -1.08172795e-08, -9.17025833e-09,  3.11598214e-09],\n",
       "        ...,\n",
       "        [-6.27535746e-10,  1.00361575e-09, -5.66244052e-10, ...,\n",
       "          1.25946951e-08,  7.87107435e-10, -1.53620583e-09],\n",
       "        [-8.38119019e-10, -6.54901966e-10,  2.79155254e-09, ...,\n",
       "         -1.43865764e-09, -3.83471743e-09, -3.53321622e-10],\n",
       "        [-7.42937600e-10,  2.40592501e-09, -1.49010526e-09, ...,\n",
       "          1.52077473e-09,  1.71245496e-09, -3.14993032e-09]], dtype=float32),\n",
       " array([ 4.84978864e-06,  4.97623262e-07, -2.36539358e-06,  8.00876307e-07,\n",
       "         2.03307968e-06, -1.52061909e-06, -1.25368470e-05, -2.03267064e-06,\n",
       "         1.31691115e-06, -8.90791489e-06,  3.97406484e-06,  4.25883718e-06,\n",
       "         5.96730752e-06,  6.23593996e-06,  2.04248590e-06, -5.66148117e-07,\n",
       "         7.70749182e-07,  1.96895166e-06, -2.93912422e-06,  1.36604979e-06,\n",
       "        -4.54772089e-06,  3.92189804e-06, -6.50420816e-06,  4.49270601e-06,\n",
       "        -1.05393474e-06, -7.99487225e-07,  1.40732607e-06, -1.08726272e-06,\n",
       "         1.94393238e-06,  2.24333007e-07,  9.34331069e-07, -3.74552747e-06,\n",
       "        -8.34017646e-06, -7.74649925e-06, -3.58634935e-07,  2.98991290e-06,\n",
       "        -1.64915775e-07,  8.58097309e-08,  2.90323806e-06,  2.08759900e-07,\n",
       "        -6.38768029e-07,  2.97030419e-06, -1.12849912e-05,  1.53176927e-07,\n",
       "        -3.52889128e-06, -4.54823385e-06, -6.58029705e-07,  2.72480816e-06,\n",
       "         1.36260979e-07, -2.56840781e-06, -1.73081742e-06, -1.72378225e-06,\n",
       "         7.37822802e-07,  3.99440296e-06, -2.07500966e-06,  5.61571687e-06,\n",
       "         1.01087394e-07, -6.50719812e-07, -6.81416122e-06,  1.15380431e-06,\n",
       "        -3.84300120e-06, -1.85452063e-06, -1.81620101e-06, -7.27636643e-06,\n",
       "        -1.24237624e-06, -4.69425231e-06,  8.79597224e-07, -2.87302055e-06,\n",
       "         1.24763164e-06, -2.23749822e-07, -2.91096853e-06, -1.89048319e-06,\n",
       "        -3.67198481e-06,  1.30157707e-06,  2.15421619e-06,  2.22487483e-06,\n",
       "        -3.21837751e-06, -1.13325859e-05, -2.77228025e-07, -6.35509377e-06,\n",
       "        -4.62308526e-06, -4.02372166e-07,  8.60004820e-06,  2.85265969e-07,\n",
       "        -3.51514063e-06, -8.56147471e-06, -9.88346414e-07,  3.89493744e-06,\n",
       "        -4.18327591e-06, -9.89638920e-07, -1.70788417e-06,  2.25707680e-07,\n",
       "         4.63134347e-06, -5.57056683e-06, -3.39726512e-06,  3.01218438e-06,\n",
       "        -3.32083710e-06, -3.87871341e-06,  3.01476757e-06, -2.37818585e-06,\n",
       "         1.06822438e-06, -1.82834776e-06,  3.12046836e-06,  1.77998902e-06,\n",
       "        -3.52948496e-06,  4.40515578e-06, -4.17085585e-06, -5.08247649e-06,\n",
       "         4.15559271e-06, -2.06717414e-06,  3.90307969e-06, -1.86075499e-06,\n",
       "         3.85759586e-06, -3.87710861e-06, -2.95513837e-06,  1.47241656e-06,\n",
       "        -1.13841843e-05,  6.37915491e-07, -1.74241450e-06,  2.07561675e-06,\n",
       "        -3.29164163e-06,  1.93751612e-06, -3.00753254e-06,  5.10906284e-06,\n",
       "        -3.45149078e-06,  6.77924436e-06,  2.17948326e-09, -4.84325597e-07,\n",
       "        -1.64286382e-02, -1.53835295e-02,  2.38920981e-03,  1.34218717e-03,\n",
       "        -6.10912871e-03,  2.86675431e-03,  2.49815993e-02,  1.36532150e-02,\n",
       "         3.64595242e-02,  2.57201269e-02,  2.20269784e-02, -2.75564399e-02,\n",
       "        -1.45649482e-02,  2.53319852e-02,  2.90166168e-03, -8.98219552e-03,\n",
       "        -1.83550920e-02, -1.84789277e-03, -2.31229644e-02, -6.67919731e-03,\n",
       "        -1.06480578e-02,  3.09583172e-02, -1.00040492e-02,  3.93743999e-02,\n",
       "         1.24056302e-02,  2.77428678e-03,  2.33100504e-02,  1.36435935e-02,\n",
       "        -1.38371289e-02,  8.36116495e-04,  7.39822537e-03,  2.09617196e-03,\n",
       "         2.21059006e-02,  2.45694574e-02,  3.28312926e-02, -2.13927701e-02,\n",
       "         1.82711631e-02, -4.20493260e-03, -9.52178799e-03,  2.60305312e-02,\n",
       "        -1.40389586e-02,  1.32424766e-02,  2.81298682e-02,  1.70306291e-03,\n",
       "        -2.13574339e-03, -2.33437512e-02,  5.70550561e-03, -2.03725453e-02,\n",
       "        -1.59666874e-02, -1.50145730e-02, -4.24165651e-03, -3.14354256e-04,\n",
       "         6.98263198e-03,  2.63645290e-03,  6.83157844e-03, -7.26181455e-03,\n",
       "         6.07768120e-03, -7.91554060e-03,  1.39571717e-02, -4.66868049e-03,\n",
       "         1.60522386e-03, -7.31317341e-05, -6.70425314e-03, -1.46249020e-02,\n",
       "        -8.91124271e-03, -1.89788118e-02, -5.38461027e-04, -1.28331985e-02,\n",
       "        -2.35452200e-03,  1.74910743e-02, -5.32832788e-03,  2.31142924e-03,\n",
       "         1.55373998e-02, -1.04522677e-02, -2.08230801e-02,  7.32418103e-03,\n",
       "         1.84314884e-03, -3.43840607e-02,  3.44608054e-02,  3.03360466e-02,\n",
       "         8.06057360e-05, -5.64452540e-03,  4.14420255e-02, -1.21618640e-02,\n",
       "         2.01302003e-02,  1.69844721e-02,  1.31322471e-02,  5.63747832e-04,\n",
       "         8.41845106e-03,  2.76639983e-02,  1.00773592e-02, -2.10526753e-02,\n",
       "         2.03873706e-03,  9.50566027e-05,  3.65307592e-02, -1.65375602e-02,\n",
       "        -3.85098010e-02,  1.51734864e-02, -2.90424917e-02,  3.41679249e-03,\n",
       "        -1.19270245e-02, -1.72366928e-02, -2.15276144e-02,  5.33326576e-03,\n",
       "         1.03419339e-02, -3.15921903e-02,  1.05546799e-03, -1.44244125e-02,\n",
       "        -3.72196757e-03, -2.11784039e-02,  1.91390654e-03, -2.18127435e-03,\n",
       "         1.30523480e-02,  1.39704570e-02, -3.61868017e-03, -1.90634727e-02,\n",
       "         1.96940098e-02,  2.25291774e-02,  3.13217519e-03,  1.89274792e-02,\n",
       "         1.02399345e-02,  2.81313458e-03,  5.38163818e-03, -1.70341916e-02,\n",
       "        -8.34374782e-03,  2.90635116e-02, -1.15868896e-02, -1.89420506e-02,\n",
       "         3.42744920e-06, -2.05904121e-06, -5.91453158e-07,  2.73011983e-06,\n",
       "         1.73143621e-06,  8.89819773e-10, -1.24977232e-05, -3.39057988e-06,\n",
       "         3.76766798e-06, -6.93497668e-06,  2.89040963e-06,  1.85235422e-06,\n",
       "         5.23523704e-06,  3.73648390e-06,  1.43221868e-07, -1.78509185e-06,\n",
       "        -2.33900550e-07, -1.87911951e-06, -2.40640861e-06, -1.35757989e-06,\n",
       "        -3.69767486e-06,  6.04148454e-06, -4.81892448e-06,  3.15586544e-06,\n",
       "        -4.61782463e-07,  5.85983344e-07, -9.45270244e-07, -5.44494924e-07,\n",
       "         9.69124699e-07, -1.73518941e-07, -3.13727298e-07, -2.46957711e-06,\n",
       "        -4.65772609e-06, -5.83120436e-06, -1.26456268e-06,  1.75104208e-06,\n",
       "         9.32691023e-07,  7.80654659e-07,  1.77060849e-06,  2.80749191e-06,\n",
       "        -3.18135847e-07,  1.18310459e-06, -9.33804677e-06, -4.31386269e-07,\n",
       "        -2.31071613e-06, -5.45418698e-06, -1.76636979e-06,  3.62091328e-07,\n",
       "         7.11640666e-08, -9.95305186e-07, -2.80468316e-06, -2.85376245e-07,\n",
       "         3.14465728e-06,  1.45636830e-06, -1.67895337e-06,  1.75712012e-06,\n",
       "         8.45493730e-07, -2.98019631e-06, -5.52421852e-06,  9.76023898e-07,\n",
       "        -2.73214027e-06, -7.70995825e-07, -4.84942916e-07, -6.87792453e-06,\n",
       "        -8.93933418e-07, -2.98719624e-06, -7.07734728e-07, -5.60962121e-07,\n",
       "         1.09650352e-06,  1.45477065e-06, -3.47131345e-06, -3.13061491e-07,\n",
       "        -4.73381624e-06,  1.20964228e-06,  2.48498986e-06, -2.13150361e-06,\n",
       "        -2.10024973e-06, -7.34845162e-06, -9.10260155e-07, -3.74829119e-06,\n",
       "        -3.88137050e-06, -5.52285030e-07,  4.41758721e-06,  1.48126674e-06,\n",
       "        -3.65225901e-06, -5.02260718e-06, -3.64965103e-07,  4.52275935e-06,\n",
       "        -2.57807670e-07, -2.37456106e-06, -6.62480261e-07, -5.44215823e-07,\n",
       "         4.61315949e-06, -5.84992722e-06, -4.45537080e-06,  5.00645183e-06,\n",
       "        -3.34587526e-06, -2.80198901e-06,  2.91597416e-06,  1.04351017e-07,\n",
       "         8.96395932e-07, -5.48999139e-07,  1.82063241e-06,  1.38178757e-06,\n",
       "        -1.65660447e-06,  4.14379929e-06, -1.12487783e-06, -3.27327393e-06,\n",
       "         1.48225729e-06, -3.72121281e-06,  1.17455693e-06, -3.50763003e-07,\n",
       "         3.67818711e-06, -4.98824079e-07, -7.23353196e-07,  1.89887987e-06,\n",
       "        -5.69123313e-06, -3.28650572e-07, -3.16800038e-06,  1.25967495e-06,\n",
       "        -1.81265398e-06, -1.30587637e-06, -3.26065503e-08,  7.02843454e-06,\n",
       "        -9.58032160e-07,  6.77625576e-06,  1.20417053e-06, -1.54990778e-06,\n",
       "         4.84855627e-06,  4.99528028e-07, -2.36614028e-06,  7.99283555e-07,\n",
       "         2.03473678e-06, -1.51998677e-06, -1.25347933e-05, -2.03299282e-06,\n",
       "         1.30571811e-06, -8.89705007e-06,  3.97615440e-06,  4.26144697e-06,\n",
       "         5.96925247e-06,  6.24559198e-06,  2.04062167e-06, -5.66158917e-07,\n",
       "         7.72963801e-07,  1.97022837e-06, -2.93426251e-06,  1.36505662e-06,\n",
       "        -4.54594283e-06,  3.92349011e-06, -6.50451057e-06,  4.49164781e-06,\n",
       "        -1.05940137e-06, -8.02421141e-07,  1.41146302e-06, -1.08736015e-06,\n",
       "         1.93941787e-06,  2.23708341e-07,  9.31691602e-07, -3.73955049e-06,\n",
       "        -8.33824470e-06, -7.74464661e-06, -3.59406130e-07,  2.98433201e-06,\n",
       "        -1.59542424e-07,  8.35859311e-08,  2.90467051e-06,  2.13625469e-07,\n",
       "        -6.32661170e-07,  2.97327529e-06, -1.12829694e-05,  1.57240521e-07,\n",
       "        -3.52954203e-06, -4.54595465e-06, -6.54282701e-07,  2.72696229e-06,\n",
       "         1.35824678e-07, -2.56817270e-06, -1.73083208e-06, -1.72180114e-06,\n",
       "         7.43134819e-07,  3.99137707e-06, -2.07333551e-06,  5.61745264e-06,\n",
       "         1.05315522e-07, -6.45950365e-07, -6.80912126e-06,  1.15547130e-06,\n",
       "        -3.84096757e-06, -1.85673071e-06, -1.81558141e-06, -7.27704264e-06,\n",
       "        -1.24542009e-06, -4.69786391e-06,  8.79656227e-07, -2.87318653e-06,\n",
       "         1.24958751e-06, -2.19348323e-07, -2.91162837e-06, -1.89401760e-06,\n",
       "        -3.66940822e-06,  1.30118701e-06,  2.15534737e-06,  2.23120674e-06,\n",
       "        -3.22070446e-06, -1.13223277e-05, -2.78660849e-07, -6.36302229e-06,\n",
       "        -4.62255366e-06, -4.07719597e-07,  8.60226010e-06,  2.85299507e-07,\n",
       "        -3.51189033e-06, -8.55749840e-06, -9.88012403e-07,  3.89563320e-06,\n",
       "        -4.18575974e-06, -9.87849717e-07, -1.70807516e-06,  2.26784891e-07,\n",
       "         4.62662865e-06, -5.56900341e-06, -3.39864846e-06,  3.01084765e-06,\n",
       "        -3.32027798e-06, -3.87594446e-06,  3.01238470e-06, -2.37867016e-06,\n",
       "         1.06609104e-06, -1.82682538e-06,  3.11547683e-06,  1.77450488e-06,\n",
       "        -3.52317920e-06,  4.40018675e-06, -4.17382989e-06, -5.07921459e-06,\n",
       "         4.15951718e-06, -2.06483674e-06,  3.90511195e-06, -1.86220757e-06,\n",
       "         3.86257761e-06, -3.88137869e-06, -2.95122800e-06,  1.47707988e-06,\n",
       "        -1.13874976e-05,  6.32850117e-07, -1.74670515e-06,  2.08023607e-06,\n",
       "        -3.29451859e-06,  1.93698907e-06, -3.01166551e-06,  5.11349072e-06,\n",
       "        -3.45025160e-06,  6.77445905e-06,  4.36742198e-09, -4.82851931e-07],\n",
       "       dtype=float32),\n",
       " array([[ 1.6195502e-04,  2.6259664e-04,  2.6021889e-04, ...,\n",
       "         -2.6432116e-07, -2.6217919e-07, -2.7061003e-07],\n",
       "        [-1.8028636e-04, -1.6475860e-04, -5.1361618e-05, ...,\n",
       "          2.3599696e-07,  2.3412808e-07,  2.4160866e-07],\n",
       "        [ 1.1282431e-04,  9.8316523e-05,  2.4488629e-05, ...,\n",
       "         -2.6288058e-07, -2.6081000e-07, -2.6912559e-07],\n",
       "        ...,\n",
       "        [-5.1959916e-05, -3.5499004e-04, -2.2984845e-04, ...,\n",
       "          3.2510320e-07,  3.2250333e-07,  3.3285042e-07],\n",
       "        [ 9.9853896e-05,  1.6094328e-04,  1.4942400e-04, ...,\n",
       "         -2.1790022e-07, -2.1614107e-07, -2.2304233e-07],\n",
       "        [ 1.4946167e-05,  2.9606792e-05, -1.3610510e-04, ...,\n",
       "          1.2841532e-07,  1.2737125e-07,  1.3143951e-07]], dtype=float32),\n",
       " array([-0.7813288 , -1.0979928 , -0.98131615, ...,  0.00198131,\n",
       "         0.00196542,  0.00202834], dtype=float32)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(grads, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> 4. Apply the optimizer to the variables/gradients tuple</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tensorflow training operation through our optimizer\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(train_op, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
